% Chapter 2

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{ Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%1.15 billion monthly active users as of June 2013
%----------------------------------------------------------------------------------------

\section{Introduction}

The number of Internet users continues to grow rapidly and today's most popular applications are Internet-based applications such as, social network,video portals, e-commerce, etc. As the Internet applications serve millions of users around the globe, the amount of generated data is also huge. Users that interacts with applications generate various data such as  click-stream data, crawled web documents, web requests, logs, etc. The greater the number of users that interact with system the more data is generated. For example, the number of monthly active users on Facebook; the largest social network in the world has been 1.15 billion users as of June 2013.\cite{fb1} The interaction of such huge number of users with facebook application generates huge dataset. Such dataset is potentially a gold mine for the companies to understand access pattern and ad revenue of the companies\cite{mat1}.\\ 

 Traditional database systems have difficulty to process large datasets, hence new data management and processing techniques are required to process datasets\cite{ieee1}. Engineers at Google were solving the same problem of building production search indexes again and again. Finally, they invented MapReduce(MapReduce was inspired by older ideas from the functional programming, distributed computing, and database communities) as a solution to build production search indexes, but it has since been used by many other industries like Facebook, Yahoo!, etc.\\ 

MapReduce is a programming paradigm used to process large datasets and Hadoop is an open source implementation of MapReduce. Hadoop runs on commodity computers and processes the data in a distributed and parallel manner. The machines forming an Hadoop cluster runs in a master-slave pattern, where the master is called namenode and slaves are referred as datanodes. Hadoop processes the data using key/value pattern, where key is the data portion to be searched, and value is the result for searched key. The datasets are the work-units or so called "jobs" that needs to be processed by Hadoop, Hadoop splits jobs into tasks by subdividing the dataset into small, fixed-sized chunks of data, tasks are then scheduled using Hadoop scheduler for execution. The schedulers has important role for the performance of Hadoop, the literature suggested various scheduling algorithm for optimizing Hadoop, using which multiple different jobs can be served by the cluster. \\
 

 Processing large dataset requires substantial computing resources, which maybe too costly for companies to buy and operate. As a solution,  "Cloud Computing" is a technology that allows organization to rent the necessary computational resources and pay based on their usage. Cloud services are provided through network connection ( usually through Internet ), where clients can use computational resources to store, process and retrieve data according to their needs. An example of such cloud computing resources is AMAZON Elastic Cloud 2 (AMAZON EC2) cloud services, where companies can rent resources to install or run applications according to their needs. The provided resources in the cloud are virtualized environment, where more than one Virtual Machines (VMs) are placed on a single physical machine. The collocation of VMs may lead to poor performance of applications; this is because of contention of resources in the absence of perfect resource isolation.  The impact of VMs collocation for Hadoop is analysed in this thesis. The new version of Hadoop (YARN) with optimized schedulers such as capacity share and fairshare schedulers, provides great opportunity for multiple organizations to submit and process different jobs. The optimized Hadoop scheduler provides the ability to divide( for example percentile based) computational resources of a single Hadoop cluster among multiple organizations, where each organization can utilize its own share of the cluster. On one hand , sharing single Hadoop cluster reduces the computational cost for the organizations, on the other hand, using a shared Hadoop cluster, the submitted jobs from one organization may result in negative impact on jobs of other organization(s).
 
We evaluate the performance of Hadoop scheduler based on job completion time for each scheduler and analyse the result by comparison of the results for selected set of optimized Hadoop schedulers. We also evaluate the fairness of job completion time in comparative manner for all the schedulers. The fairness is the maximum minus minimum job completion time. \\
 

%The adoption of information technology to various area of human life and an Internet connecting world leads to massive growth
%in the amount of data produced. We live in data explosion era, in which the data sets being processed and analysed are called"big %data" .. To understand quickly the dynamic behaviour of the users in Facebook, the process and analyse of big data is needed. 
%click-stream data for user actions are the main sources for developers and operators to diagnose problems in production.



\section{Objective}

  Mos of the service provided by the cloud operators are not free, to use services companies may pay based on services or resources they use. Hadoop is state-of-the-art tool to process large datasets. Using optimized job schedulers of Hadoop, organizations can share use a single Hadoop cluster(also called multi-tenant Hadoop cluster) running on the cloud. As the cloud resources used by Hadoop are rented, the organizations tries to fully utilize the resources. The objective of this work is to analyse the performance of Hadoop optimized schedulers. More precisely, the performance of capacity share and fairshare schedulers of Hadoop are analysed in this thesis. For both schedulers, the effects of speculative task execution is also analysed.\\
 
 For all the schedulers, the job completion time is analysed and compared. Since optimized Hadoop version provides the  opportunity for multi-tenancy of Hadoop clusters for multiple organizations, the impact of collocation of datanodes is analysed. The collocation of datanodes are analysed in two cases. In the first case, two datanodes belonging to the same Hadoop cluster are collocated on the same physical machine. In the second case, two datanodes from different Hadoop clusters are placed on top of single physical machine. In both cases, performance of Hadoop is analysed to find how collocation of datanodes can affect the performance of Hadoop. \\  
 



\section{Contribution}

The thesis covers the analysis of optimizations deployed in Hadoop (YARN). More precisely, this work addresses the implementation , analysis and evaluation of Hadoop performance and effects of collocation for Hadoop datanodes. Where job is the unit of work to be processed by Hadoop, the focus of the work is to analyse job completion time using different Hadoop schedulers. The time difference between various submitted jobs is another parameter analysed as fairness among job completion time. The contribution of this thesis work is:
\begin{itemize}
 \item{ For a range of workloads and parameters,  the collocation of datanodes has negative impact on performance of schedulers. While fairshare scheduler provides better fairness among job completion time, it has poor performance for job completion time in comparison to capacity share scheduler. For small size jobs(five GB each), the speculative task execution does not always bring better performance.  }   
\end{itemize} 



\section{Thesis Overview}

The reminder of this thesis is organized as follow. In chapter 2 the background information is explained. Chapter 3 describes Hadoop optimization and chapter 4 explains the methodology and experimental environment. Chapter 5 provides detailed information evaluation of the experiment where detail of each experiments along with results and discussions about result of experiment is explained. Chapter 6 provides analysis of cloud computing service for Afghanistan market. The last chapter, chapter 7 presents the conclusion of thesis and future work. 
