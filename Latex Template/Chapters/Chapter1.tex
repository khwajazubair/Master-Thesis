% Chapter 2

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{ Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%1.15 billion monthly active users as of June 2013
%----------------------------------------------------------------------------------------

\section{Introduction}

The number of internet users grows rapidly and today's most popular applications are internet based applications such as, social media, e-commerce,etc. As the Internet applications serves millions of users around the globe, so the amount generated data is also huge. Users that interacts with internet generates various data such as  click-stream data,crawled web documents, web requests, logs etc. The greater the number of users interact with system the more data is going to generate.For example, the number of monthly active users on Facebook; the largest social network in the world has been 1.15 billion users as on June 2013.\cite{fb1} The interaction of such huge number of users with facebook application generates huge dataset. Such dataset is potential gold mine for the companies to understand access pattern and ad revenue of the companies\cite{mat1}.\\ 

 Traditional database systems have difficulty to process large datasets, hence new data management and processing techniques is required to process datasets\cite{ieee1}. Engineers at Google were solving the same problem of building production search indexes again and again. Finally, they invented MapReduce(MapReduce was inspired by older ideas from the functional programming, distributed computing, and database communities) as solution to build production search indexes, but it has since been used by many other industries like Facebook, Yahoo!, etc.\\ 

MapReduce is programming paradigm used to process large datasets and Hadoop is an open source implementation of MapReduce. Hadoop runs on commodity computers and processes the data in distributed, parallel manner. The machines forming Hadoop cluster runs in master-slave pattern, where master is called namenode and slaves are referred as datanodes. Hadoop process the data using key/value pattern, where key is the data portion to be searched, and value is the result for searched key. Hadoop splits dataset into small fixed size data units called jobs, jobs are then scheduled using Hadoop scheduler for execution. The schedulers has important role in performance of Hadoop and literature suggested various scheduling algorithm for optimization of Hadoop, using which multiple different jobs can be served by the cluster. \\
 

Processing of large dataset requires more computation resources, which maybe costly for companies to buy and prepare required computational resources. As solution,  "Cloud Computing" is a technology , where companies can rent the computational resources to process the datasets. Cloud services are provided through network connection ( usually through Internet ), where clients can use computational resources to stored,process and retrieve data according to their need. An example of such cloud computing resources is AMAZON Elastic Cloud 2 (AMAZON EC2) cloud services, where companies can rent resources to install or run application according to their need. The provided resources in the cloud are virtualized environment, where more than one Virtual Machines (VMs) are placed on single physical machine. The co-location of VMs lead to poor performance of applications, this is because of contention of resources in the absence of perfect resource isolation.  The impact of VMs co-location for Hadoop is analysed in this document. The new version of Hadoop (YARN) with optimized schedulers such as capacity share and fairshare schedulers, provides great opportunity for the entire/subdivisions of organization to submit and process different jobs. The optimized Hadoop scheduler provides the facility to divide( for example percentile based) computational resources of single Hadoop cluster among multiple organizations, where each organization can utilize its own share portion of the cluster. In one hand , sharing single Hadoop cluster reuduces the computational cost for the organizations, on the other hand, using share Hadoop cluster, the submitted jobs, from one organization may affect jobs of other organization. Using optimized Hadoop schedulers, the fairness of job completion time and total job completion time for submitted jobs are evaluated as Hadoop performance analysis.\\


%The adoption of information technology to various area of human life and an internet connecting world leads to massive growth
%in the amount of data produced. We live in data explosion era, in which the data sets being processed and analysed are called"big %data" .. To understand quickly the dynamic behaviour of the users in Facebook, the process and analyse of big data is needed. 
%click-stream data for user actions are the main sources for developers and operators to diagnose problems in production.



\section{Objective}

 For the processing of large datasets, either an organization must have enough computational resources, or rent computational resources from cloud service. Not all the service provide by the cloud operators are free, to use services companies may pay based on services or resources they use. Hadoop is fair tool to process large datasets, using optimized job schedulers of Hadoop, organizations can share use single Hadoop cluster(also called multi-tenant Hadoop cluster) running on the cloud. As the cloud resources used by Hadoop are rented, so the organizations tries to fully utilize the resources. The objective of this work is to analyse the performance of Hadoop optimized schedulers. More precisely, the performance of capacity and fairshare schedulers of Hadoop are analysed in this thesis work. For both schedulers, the effects of speculative task execution is also analysed.  The speculative tasks execution is added as default mechanism in latest Hadoop version called YARN.\\
 
 For all the schedulers, the job completion time is analysed and compared. Since, optimized Hadoop version provides the great opportunity for multi-tenancy of Hadoop cluster for multiple organizations, hence, the impact of co-location of datanodes (datanode is the machine in Hadoop cluster used to store and process data) is analysed. The co-location of datanodes are analysed in two cases. In first case, two datanodes belonging to single Hadoop cluster are placed on top of single physical machine. In second case, two datanodes from different Hadoop clusters are placed on top of single physical machine. In both cases, performance of Hadoop is analysed to find how co-location of datanodes can affect the performance of Hadoop. \\  
 



\section{Contribution}

The thesis covers the analyses of optimization deployed in Hadoop (YARN). More precisely, this work addresses the implementation , analyses and evaluation of Hadoop performance with different number of "reducers". Where job is the unit of work to be processed by Hadoop, the focus of the work is to analyse job completion time using different Hadoop schedulers. The time difference between various submitted jobs are another parameter analysed as fairness among job completion time. The contribution of this thesis work is:
\begin{itemize}
 \item{ While fairshare scheduler provides better fairness among job completion time, it has poor performance for job completion time comparing to capacity scheduler. For small size jobs(five GB each), the speculative task execution does not bring better performance always. For range of certain workloads and parameters,  the co-location of datanodes has negative impact on performance of schedulers. }   
\end{itemize} 



\section{Thesis Overview}

The thesis consist of seven chapters as follow. Chapter 1 is about introduction of thesis and topic covered in this thesis. In chapter 2 the background information is explained. Chapter 3 is about Hadoop optimization and chapter 4 explains the methodology, experimental environment. Chapter 5 provides detail information evaluation of the experiment where detail of each experiments along with results discussions about result of experiment is explained. Chapter 6 provides analysis of cloud computing service for Afghanistan market. The last chapter, chapter 7 is wrap up of the work with conclusion of thesis and future work. The bibliography and appendixes is attached at the end of the thesis. 

