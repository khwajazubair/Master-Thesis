% Chapter Template

\chapter{Conclusions} % Main chapter title

\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 7. \emph{Conclusions}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Conclusions}
 
 
 The experimental results explained in chapter \ref{Chapter5} gives the idea that Hadoop optimizations does not improve the performance of Hadoop for every dataset process. For cloud services where physical computational resources are shared among multiple organizations to run Hadoop cluster(s), using capacity share scheduler of Hadoop is better choice in comparison to fairshare scheduler. Overall, the capacity scheduler of Hadoop has good performance in term of job completion time, but it has poor fairness results for job completion time. \\
 
 As the name explains, fairshare scheduler of Hadoop has better fairness in all the cases in comparison to capacity share scheduler of Hadoop, but it has poor performance than capacity share scheduler. For submitted jobs to Hadoop cluster from single or multiple organizations, in case fairness is important, than fairshare scheduler is better choice, otherwise , capacity scheduler has better performance. \\
 
 The collocation of more than one VM acting as datanode on a single physical machine, degrades the performance  of Hadoop. Collocation of VMs (datanodes)‌ from same cluster has better results in comparison to placement of VMs from different Hadoop clusters. Though the performance of Hadoop schedulers are degraded by collocation, but capacity share scheduler is more robust to collocation of datanodes.\\
 
 The thesis explored the analysis of speculative task executions by Hadoop schedulers. While the expectation is to increase the performance of Hadoop by speculative tasks execution, the evaluated results in chapter \ref{Chapter5} shows that this assumption is not hold always. This is because, speculative execution of tasks requires more resources to be utilized, utilization of resources decreases the performance of Hadoop for small jobs.   \\
 
 The selection of fair number of reducers plays important role on performance of Hadoop. The results evaluated in chapter \ref{Chapter5} explains the idea that selection of number of reducer from 25\% to 50\% of mappers number leads to best result for the mapper, reducer combination.  
 
 
 Considering the current situation of Afghanistan, where ICT infrastructure is very poor, security and lack of experts for the IT‌ fields are challenges, running the services on cloud operator has difficulty of unstable Internet. The projects such as NFO‌ brings the hope to have stable infrastructure for the ICT where organization can rely on cloud services, but there are number of security and political challenges to the completion of the ICT‌ projects.  

\section{Future Work}

 We addressed the evaluation and analysis of of Hadoop performance for set of schedulers using Terasort workload. We tune number of reducers, to see the impact of change on performance of Hadoop. There are possible extension to this analysis, where one can run similar experiments with different workloads and jobs sizes, to validate the performance evaluation for all the cases. Also, it is possible to tune any other parameter of Hadoop such as queue configuration of schedulers, submit of various job sizes, resource partitioning, etc, and analyze the performance of results for optimized Hadoop schedulers. The effect of collocation can be analysed for the cases where Hadoop nodes are collocated with other application in the data-centre. The test of similar experiment on bare-bone physical machines are another research field, because All the experiments are executed on VMs, which possibly may not provide the same results for execution on top bare-metal physical machines.



